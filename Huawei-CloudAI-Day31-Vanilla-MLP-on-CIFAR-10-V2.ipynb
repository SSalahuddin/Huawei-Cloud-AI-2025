{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![01.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "---\n",
        "\n",
        "# **Huawei Cloud AI Training Day 31 - Part B**\n"
      ],
      "metadata": {
        "id": "IziBPhnI-5YM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjWfst27UTf8"
      },
      "source": [
        "# Vanilla MLP on CIFAR-10 (Version 2)\n",
        "\n",
        "### Standardization after normalization → steadier training.\n",
        "\n",
        "### Bigger network but with L2 weight decay + Dropout 0.2 → capacity without overfitting too hard.\n",
        "\n",
        "### BatchNorm before ReLU → faster, more stable convergence.\n",
        "\n",
        "### LR scheduler (ReduceLROnPlateau) → automatic LR tuning.\n",
        "\n",
        "### EarlyStopping (+ checkpoint) → train longer safely and keep the best weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L_KDB7nUSKF"
      },
      "outputs": [],
      "source": [
        "import os, random, numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47tIFUiaUf0c"
      },
      "outputs": [],
      "source": [
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY5E2ZyNUhTk"
      },
      "outputs": [],
      "source": [
        "# 1) Load CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "y_train = y_train.squeeze();\n",
        "y_test = y_test.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuIO6Y0GU5AX"
      },
      "outputs": [],
      "source": [
        "# 2) Normalize + Standardize\n",
        "# scale to [0,1]\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test  = x_test.astype(\"float32\")  / 255.0\n",
        "\n",
        "# per-channel standardization using train stats\n",
        "mean = x_train.mean(axis=(0,1,2), keepdims=True)\n",
        "std  = x_train.std(axis=(0,1,2), keepdims=True) + 1e-7\n",
        "x_train = (x_train - mean) / std\n",
        "x_test  = (x_test  - mean) / std\n",
        "\n",
        "# flatten for MLP\n",
        "x_train = x_train.reshape(len(x_train), -1)\n",
        "x_test  = x_test.reshape(len(x_test),  -1)\n",
        "\n",
        "num_classes = 10\n",
        "input_dim = x_train.shape[1]  # 3072"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "F_KVkoWZUvV0",
        "outputId": "2c0c8787-1cd5-4101-82a3-e0452141d4fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,718,592</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,648</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">294,912</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,930</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │     \u001b[38;5;34m4,718,592\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │         \u001b[38;5;34m6,144\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │     \u001b[38;5;34m1,179,648\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │         \u001b[38;5;34m3,072\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │       \u001b[38;5;34m294,912\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │         \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │        \u001b[38;5;34m73,728\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,930\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,280,330</span> (23.96 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,280,330\u001b[0m (23.96 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,274,570</span> (23.94 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,274,570\u001b[0m (23.94 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> (22.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,760\u001b[0m (22.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 3) Build a stronger, regularized MLP\n",
        "def build_mlp(input_dim, num_classes, l2=1e-4, drop=0.2):\n",
        "    reg = regularizers.l2(l2)\n",
        "\n",
        "    def block(x, units, drop):\n",
        "        x = layers.Dense(units, use_bias=False, kernel_regularizer=reg)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.Dropout(drop)(x)\n",
        "        return x\n",
        "\n",
        "    inputs = keras.Input(shape=(input_dim,))\n",
        "    x = inputs\n",
        "    x = block(x, 1536, drop)  # larger first layer\n",
        "    x = block(x, 768,  drop)\n",
        "    x = block(x, 384,  drop)\n",
        "    x = block(x, 192,  drop)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_mlp(input_dim, num_classes, l2=1e-4, drop=0.2)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k0a2r6OblvE"
      },
      "outputs": [],
      "source": [
        "# 4) Callbacks: Early Stop, Reduce LR, Best Checkpoint\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\", patience=8, restore_best_weights=True\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_accuracy\", factor=0.5, patience=3, min_lr=1e-6, verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_mlp.keras\", monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SteoK4LkU8Ws",
        "outputId": "33a7d4bb-7444-4380-abe6-673815b3326f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.3058 - loss: 2.3597\n",
            "Epoch 1: val_accuracy improved from -inf to 0.41680, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 321ms/step - accuracy: 0.3061 - loss: 2.3587 - val_accuracy: 0.4168 - val_loss: 2.0470 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.4314 - loss: 1.9526\n",
            "Epoch 2: val_accuracy improved from 0.41680 to 0.47320, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 294ms/step - accuracy: 0.4315 - loss: 1.9523 - val_accuracy: 0.4732 - val_loss: 1.8402 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.4834 - loss: 1.8032\n",
            "Epoch 3: val_accuracy improved from 0.47320 to 0.50340, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 281ms/step - accuracy: 0.4834 - loss: 1.8031 - val_accuracy: 0.5034 - val_loss: 1.7303 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.5057 - loss: 1.7090\n",
            "Epoch 4: val_accuracy improved from 0.50340 to 0.51340, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 274ms/step - accuracy: 0.5057 - loss: 1.7088 - val_accuracy: 0.5134 - val_loss: 1.6751 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.5278 - loss: 1.6342\n",
            "Epoch 5: val_accuracy improved from 0.51340 to 0.53040, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 284ms/step - accuracy: 0.5278 - loss: 1.6342 - val_accuracy: 0.5304 - val_loss: 1.6298 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.5414 - loss: 1.5873\n",
            "Epoch 6: val_accuracy improved from 0.53040 to 0.53960, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 272ms/step - accuracy: 0.5414 - loss: 1.5872 - val_accuracy: 0.5396 - val_loss: 1.6083 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.5557 - loss: 1.5493\n",
            "Epoch 7: val_accuracy did not improve from 0.53960\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.5557 - loss: 1.5493 - val_accuracy: 0.5354 - val_loss: 1.6116 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.5674 - loss: 1.5146\n",
            "Epoch 8: val_accuracy improved from 0.53960 to 0.54320, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 265ms/step - accuracy: 0.5674 - loss: 1.5146 - val_accuracy: 0.5432 - val_loss: 1.6016 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.5760 - loss: 1.4873\n",
            "Epoch 9: val_accuracy improved from 0.54320 to 0.54480, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 264ms/step - accuracy: 0.5760 - loss: 1.4873 - val_accuracy: 0.5448 - val_loss: 1.5909 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.5863 - loss: 1.4729\n",
            "Epoch 10: val_accuracy did not improve from 0.54480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 273ms/step - accuracy: 0.5863 - loss: 1.4728 - val_accuracy: 0.5422 - val_loss: 1.6197 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.5959 - loss: 1.4512\n",
            "Epoch 11: val_accuracy improved from 0.54480 to 0.55580, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 276ms/step - accuracy: 0.5959 - loss: 1.4511 - val_accuracy: 0.5558 - val_loss: 1.5874 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.6028 - loss: 1.4320\n",
            "Epoch 12: val_accuracy did not improve from 0.55580\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 275ms/step - accuracy: 0.6028 - loss: 1.4319 - val_accuracy: 0.5462 - val_loss: 1.6142 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.6104 - loss: 1.4247\n",
            "Epoch 13: val_accuracy did not improve from 0.55580\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 259ms/step - accuracy: 0.6104 - loss: 1.4247 - val_accuracy: 0.5552 - val_loss: 1.5980 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.6171 - loss: 1.4000\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.55580\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 264ms/step - accuracy: 0.6171 - loss: 1.4000 - val_accuracy: 0.5470 - val_loss: 1.6245 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.6484 - loss: 1.3217\n",
            "Epoch 15: val_accuracy improved from 0.55580 to 0.56800, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 271ms/step - accuracy: 0.6485 - loss: 1.3215 - val_accuracy: 0.5680 - val_loss: 1.5579 - learning_rate: 5.0000e-04\n",
            "Epoch 16/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.6739 - loss: 1.2394\n",
            "Epoch 16: val_accuracy did not improve from 0.56800\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 262ms/step - accuracy: 0.6739 - loss: 1.2393 - val_accuracy: 0.5626 - val_loss: 1.5743 - learning_rate: 5.0000e-04\n",
            "Epoch 17/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.6847 - loss: 1.2010\n",
            "Epoch 17: val_accuracy did not improve from 0.56800\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 278ms/step - accuracy: 0.6847 - loss: 1.2009 - val_accuracy: 0.5616 - val_loss: 1.5888 - learning_rate: 5.0000e-04\n",
            "Epoch 18/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.6924 - loss: 1.1723\n",
            "Epoch 18: val_accuracy improved from 0.56800 to 0.57140, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 263ms/step - accuracy: 0.6924 - loss: 1.1723 - val_accuracy: 0.5714 - val_loss: 1.5841 - learning_rate: 5.0000e-04\n",
            "Epoch 19/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.7042 - loss: 1.1437\n",
            "Epoch 19: val_accuracy improved from 0.57140 to 0.57220, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 270ms/step - accuracy: 0.7042 - loss: 1.1436 - val_accuracy: 0.5722 - val_loss: 1.6208 - learning_rate: 5.0000e-04\n",
            "Epoch 20/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.7142 - loss: 1.1219\n",
            "Epoch 20: val_accuracy did not improve from 0.57220\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 270ms/step - accuracy: 0.7143 - loss: 1.1218 - val_accuracy: 0.5696 - val_loss: 1.6154 - learning_rate: 5.0000e-04\n",
            "Epoch 21/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.7244 - loss: 1.0903\n",
            "Epoch 21: val_accuracy did not improve from 0.57220\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 261ms/step - accuracy: 0.7244 - loss: 1.0903 - val_accuracy: 0.5718 - val_loss: 1.6320 - learning_rate: 5.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.7289 - loss: 1.0785\n",
            "Epoch 22: val_accuracy improved from 0.57220 to 0.57580, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 264ms/step - accuracy: 0.7289 - loss: 1.0785 - val_accuracy: 0.5758 - val_loss: 1.6563 - learning_rate: 5.0000e-04\n",
            "Epoch 23/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.7388 - loss: 1.0512\n",
            "Epoch 23: val_accuracy did not improve from 0.57580\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 261ms/step - accuracy: 0.7388 - loss: 1.0511 - val_accuracy: 0.5626 - val_loss: 1.6874 - learning_rate: 5.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.7488 - loss: 1.0269\n",
            "Epoch 24: val_accuracy did not improve from 0.57580\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 280ms/step - accuracy: 0.7488 - loss: 1.0269 - val_accuracy: 0.5712 - val_loss: 1.6980 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.7576 - loss: 1.0066\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.57580\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 258ms/step - accuracy: 0.7576 - loss: 1.0066 - val_accuracy: 0.5742 - val_loss: 1.7090 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.7802 - loss: 0.9515\n",
            "Epoch 26: val_accuracy improved from 0.57580 to 0.58500, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 275ms/step - accuracy: 0.7803 - loss: 0.9513 - val_accuracy: 0.5850 - val_loss: 1.7030 - learning_rate: 2.5000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8066 - loss: 0.8723\n",
            "Epoch 27: val_accuracy did not improve from 0.58500\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 266ms/step - accuracy: 0.8066 - loss: 0.8722 - val_accuracy: 0.5820 - val_loss: 1.7216 - learning_rate: 2.5000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8221 - loss: 0.8256\n",
            "Epoch 28: val_accuracy did not improve from 0.58500\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 264ms/step - accuracy: 0.8222 - loss: 0.8255 - val_accuracy: 0.5760 - val_loss: 1.7863 - learning_rate: 2.5000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8294 - loss: 0.7960\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.58500\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 274ms/step - accuracy: 0.8294 - loss: 0.7960 - val_accuracy: 0.5800 - val_loss: 1.8004 - learning_rate: 2.5000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8414 - loss: 0.7620\n",
            "Epoch 30: val_accuracy improved from 0.58500 to 0.58940, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 278ms/step - accuracy: 0.8414 - loss: 0.7618 - val_accuracy: 0.5894 - val_loss: 1.7445 - learning_rate: 1.2500e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8625 - loss: 0.7058\n",
            "Epoch 31: val_accuracy improved from 0.58940 to 0.59540, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 260ms/step - accuracy: 0.8626 - loss: 0.7057 - val_accuracy: 0.5954 - val_loss: 1.7494 - learning_rate: 1.2500e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8722 - loss: 0.6727\n",
            "Epoch 32: val_accuracy improved from 0.59540 to 0.59740, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 259ms/step - accuracy: 0.8722 - loss: 0.6726 - val_accuracy: 0.5974 - val_loss: 1.7793 - learning_rate: 1.2500e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.8806 - loss: 0.6510\n",
            "Epoch 33: val_accuracy did not improve from 0.59740\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 267ms/step - accuracy: 0.8806 - loss: 0.6509 - val_accuracy: 0.5964 - val_loss: 1.8078 - learning_rate: 1.2500e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.8876 - loss: 0.6261\n",
            "Epoch 34: val_accuracy did not improve from 0.59740\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 272ms/step - accuracy: 0.8876 - loss: 0.6261 - val_accuracy: 0.5954 - val_loss: 1.8245 - learning_rate: 1.2500e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.8910 - loss: 0.6152\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.59740\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 259ms/step - accuracy: 0.8910 - loss: 0.6151 - val_accuracy: 0.5974 - val_loss: 1.8513 - learning_rate: 1.2500e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.8986 - loss: 0.5926\n",
            "Epoch 36: val_accuracy improved from 0.59740 to 0.59820, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 263ms/step - accuracy: 0.8987 - loss: 0.5925 - val_accuracy: 0.5982 - val_loss: 1.8524 - learning_rate: 6.2500e-05\n",
            "Epoch 37/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9086 - loss: 0.5630\n",
            "Epoch 37: val_accuracy improved from 0.59820 to 0.60020, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 270ms/step - accuracy: 0.9086 - loss: 0.5629 - val_accuracy: 0.6002 - val_loss: 1.8511 - learning_rate: 6.2500e-05\n",
            "Epoch 38/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9124 - loss: 0.5464\n",
            "Epoch 38: val_accuracy improved from 0.60020 to 0.60200, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 276ms/step - accuracy: 0.9125 - loss: 0.5464 - val_accuracy: 0.6020 - val_loss: 1.8689 - learning_rate: 6.2500e-05\n",
            "Epoch 39/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9178 - loss: 0.5371\n",
            "Epoch 39: val_accuracy did not improve from 0.60200\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 269ms/step - accuracy: 0.9178 - loss: 0.5371 - val_accuracy: 0.5958 - val_loss: 1.8792 - learning_rate: 6.2500e-05\n",
            "Epoch 40/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9200 - loss: 0.5229\n",
            "Epoch 40: val_accuracy did not improve from 0.60200\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 263ms/step - accuracy: 0.9200 - loss: 0.5229 - val_accuracy: 0.6008 - val_loss: 1.8967 - learning_rate: 6.2500e-05\n",
            "Epoch 41/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9227 - loss: 0.5148\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.60200\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 274ms/step - accuracy: 0.9227 - loss: 0.5148 - val_accuracy: 0.5982 - val_loss: 1.9126 - learning_rate: 6.2500e-05\n",
            "Epoch 42/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9236 - loss: 0.5065\n",
            "Epoch 42: val_accuracy did not improve from 0.60200\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 260ms/step - accuracy: 0.9236 - loss: 0.5064 - val_accuracy: 0.6008 - val_loss: 1.9044 - learning_rate: 3.1250e-05\n",
            "Epoch 43/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9341 - loss: 0.4835\n",
            "Epoch 43: val_accuracy improved from 0.60200 to 0.60340, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 259ms/step - accuracy: 0.9342 - loss: 0.4834 - val_accuracy: 0.6034 - val_loss: 1.9131 - learning_rate: 3.1250e-05\n",
            "Epoch 44/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9357 - loss: 0.4745\n",
            "Epoch 44: val_accuracy did not improve from 0.60340\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 264ms/step - accuracy: 0.9357 - loss: 0.4745 - val_accuracy: 0.5996 - val_loss: 1.9272 - learning_rate: 3.1250e-05\n",
            "Epoch 45/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9377 - loss: 0.4732\n",
            "Epoch 45: val_accuracy did not improve from 0.60340\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 268ms/step - accuracy: 0.9377 - loss: 0.4732 - val_accuracy: 0.6032 - val_loss: 1.9457 - learning_rate: 3.1250e-05\n",
            "Epoch 46/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9376 - loss: 0.4681\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.60340\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 272ms/step - accuracy: 0.9376 - loss: 0.4681 - val_accuracy: 0.6022 - val_loss: 1.9434 - learning_rate: 3.1250e-05\n",
            "Epoch 47/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9389 - loss: 0.4629\n",
            "Epoch 47: val_accuracy improved from 0.60340 to 0.60480, saving model to best_mlp.keras\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 255ms/step - accuracy: 0.9389 - loss: 0.4629 - val_accuracy: 0.6048 - val_loss: 1.9538 - learning_rate: 1.5625e-05\n",
            "Epoch 48/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9409 - loss: 0.4556\n",
            "Epoch 48: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 273ms/step - accuracy: 0.9410 - loss: 0.4556 - val_accuracy: 0.6034 - val_loss: 1.9550 - learning_rate: 1.5625e-05\n",
            "Epoch 49/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9479 - loss: 0.4466\n",
            "Epoch 49: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 273ms/step - accuracy: 0.9479 - loss: 0.4466 - val_accuracy: 0.6018 - val_loss: 1.9617 - learning_rate: 1.5625e-05\n",
            "Epoch 50/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9441 - loss: 0.4487\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 266ms/step - accuracy: 0.9441 - loss: 0.4487 - val_accuracy: 0.6030 - val_loss: 1.9603 - learning_rate: 1.5625e-05\n",
            "Epoch 51/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9442 - loss: 0.4478\n",
            "Epoch 51: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 254ms/step - accuracy: 0.9442 - loss: 0.4478 - val_accuracy: 0.6014 - val_loss: 1.9714 - learning_rate: 7.8125e-06\n",
            "Epoch 52/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9481 - loss: 0.4391\n",
            "Epoch 52: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 262ms/step - accuracy: 0.9481 - loss: 0.4391 - val_accuracy: 0.6024 - val_loss: 1.9718 - learning_rate: 7.8125e-06\n",
            "Epoch 53/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9492 - loss: 0.4363\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 257ms/step - accuracy: 0.9492 - loss: 0.4363 - val_accuracy: 0.6036 - val_loss: 1.9699 - learning_rate: 7.8125e-06\n",
            "Epoch 54/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9472 - loss: 0.4389\n",
            "Epoch 54: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 261ms/step - accuracy: 0.9473 - loss: 0.4389 - val_accuracy: 0.6038 - val_loss: 1.9717 - learning_rate: 3.9063e-06\n",
            "Epoch 55/60\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9491 - loss: 0.4339\n",
            "Epoch 55: val_accuracy did not improve from 0.60480\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 267ms/step - accuracy: 0.9491 - loss: 0.4339 - val_accuracy: 0.6038 - val_loss: 1.9703 - learning_rate: 3.9063e-06\n"
          ]
        }
      ],
      "source": [
        "# 5) Train longer (early stopping will cap it)\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=60,\n",
        "    batch_size=256,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPDIXy8PU_sw"
      },
      "outputs": [],
      "source": [
        "# 6) Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\n[Improved MLP] Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "y_prob = model.predict(x_test, verbose=0)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "print(\"\\n[Improved MLP] Classification report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36SN4ztOTvW-"
      },
      "outputs": [],
      "source": [
        "# 7) Save final model (best also saved via checkpoint)\n",
        "#os.makedirs(\"saved_models\", exist_ok=True)\n",
        "#model.save(\"saved_models/mlp_cifar10_improved.keras\")\n",
        "#print(\"\\nSaved current model to saved_models/mlp_cifar10_improved.keras\")\n",
        "#print(\"Best checkpoint (by val_accuracy): best_mlp.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}